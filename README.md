# ğŸ§  Self-Training Code Generation AI (Python Instruction â†’ Script)

Proyek ini membangun sistem **self-training AI** untuk menghasilkan kode Python dari instruksi teks natural. Model akan:
- Menghasilkan skrip berdasarkan instruksi
- Mengevaluasi hasilnya
- Mencatat yang gagal dan memperbaikinya sendiri
- Menyaring hasil dengan seleksi semantik
- Mengulang proses secara otomatis

---

## ğŸ“ Struktur Folder

```bash
Train_Ai/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ dataset.jsonl            # Dataset utama (instruction, input, output="")
â”‚   â”œâ”€â”€ generated.jsonl          # Output yang berhasil dijalankan
â”‚   â”œâ”€â”€ final_dataset.jsonl      # Output yang lolos seleksi semantik (siap fine-tune)
â”‚   â”œâ”€â”€ rejected_semantic.jsonl  # Output yang gagal seleksi semantik
â”‚   â”œâ”€â”€ failed_outputs/
â”‚   â”‚   â”œâ”€â”€ errors.jsonl         # Output gagal saat dieksekusi
â”‚   â”‚   â”œâ”€â”€ non_python.jsonl     # Output JSON / bukan kode Python
â”‚   â”‚   â””â”€â”€ too_short.jsonl      # Output terlalu pendek atau kosong
â”‚   â””â”€â”€ semantic_checker.py      # Seleksi semantik otomatis
â”œâ”€â”€ model/                       # Model Hugging Face (tokenizer, config, weights)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ loop.py                  # Main loop: generate â†’ evaluasi â†’ seleksi
â”‚   â”œâ”€â”€ generator.py             # Modul: load_model, generate_script
â”‚   â”œâ”€â”€ evaluator.py             # Modul: evaluasi runtime script Python
â”‚   â”œâ”€â”€ extract_failed_to_dataset.py  # Ekstraksi ulang data gagal ke dataset
â”‚   â””â”€â”€ download_model.py        # (Opsional) Unduh model awal dari HuggingFace
ğŸ“š Format Dataset

```{
  "instruction": "Generate a POST request with custom headers.",
  "input": "Send request to https://api.example.com/data using the requests module",
  "output": ""
}```

---

âœ… Prasyarat
Python 3.10+

Paket Python yang diperlukan:

```
pip install -r requirements.txt
requirements.txt
transformers
torch
accelerate
datasets

---

â¬‡ï¸ Download Model Hugging Face
Model akan disimpan di folder model/. Contoh:

from huggingface_hub import snapshot_download
snapshot_download(repo_id="cahya/gpt2-small-indonesian-124M", local_dir="model")
ğŸ” Menjalankan Proses Self-Training

python scripts/loop.py
Fungsi:

Menghasilkan skrip dari dataset.jsonl

Menyimpan output valid ke generated.jsonl

Mengekstrak data gagal ke errors.jsonl

Menambahkan kembali ke dataset agar bisa dilatih ulang

Menyaring hasil semantik dengan semantic_checker.py

Menulis dataset siap latih ke final_dataset.jsonl

---

ğŸ“Š Ringkasan Otomatis (Contoh Output)

ğŸ“¦ Memproses 100 item...
âœ… Script berhasil dijalankan.
âŒ Script gagal. Disimpan ke failed_outputs.
ğŸ“Š Ringkasan:
âœ… Berhasil: 60 script
âŒ Gagal: 40 script
âš ï¸ JSON: 5 | Terlalu pendek: 3 | SyntaxError: 12 | Error lain: 20

---

ğŸ” Seleksi Semantik (Cek Kualitas Output)
File semantic_checker.py melakukan pengecekan apakah kode:

Sesuai dengan URL dan kata kunci dalam instruksi

Menggunakan modul yang tepat (requests, web3, dsb)

Memiliki fungsi atau class

Tidak hanya komentar atau JSON

---

ğŸ§  Fine-Tuning
Setelah mendapatkan final_dataset.jsonl, kamu bisa melatih ulang model kamu:

from datasets import load_dataset
dataset = load_dataset("json", data_files="data/final_dataset.jsonl")
Gunakan Trainer, LoRA, atau metode fine-tuning pilihanmu.

---

ğŸ”„ Loop Tanpa Henti
Loop akan terus berjalan:

Data gagal masuk ke dataset kosong

Dilatih ulang lagi

Script membaik seiring waktu

Tidak perlu campur tangan manusia

---

ğŸ’¡ Credits
Dikembangkan oleh @jamalnggau1
Dengan bantuan ChatGPT

---

ğŸ›¡ï¸ Lisensi
MIT License â€“ bebas digunakan dan dimodifikasi.
